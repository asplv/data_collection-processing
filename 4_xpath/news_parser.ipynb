{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг новостных сайтов. XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке реализован парсинг новостей с сайтов:\n",
    "- [Новости mail.ru](https://news.mail.ru/)\n",
    "- [Яндекс новости](https://yandex.ru/news/)\n",
    "- [Lenta.ru](https://lenta.ru/)\n",
    "\n",
    "Результаты сохраняются в коллекцию базы news, содержащую следующие ключи:\n",
    "- Id объекта\n",
    "- Дата публикации\n",
    "- Время публикации\n",
    "- Заголовок новости\n",
    "- Cсылка на новость\n",
    "- Название источника\n",
    "- Ссылка на источник (если ресурс предоставляет, имеется ссылка на саму новость в источнике)\n",
    "\n",
    "\n",
    "Если какой-то из элементов не найден в поле записывается значение None. Исключение - дата и время - в случае их отсутствия ставится текущее время и дата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['news_parser_db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = db.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\n",
    "'января': '01',\n",
    "'февраля': '02',\n",
    "'марта': '03',\n",
    "'апреля': '04',\n",
    "'мая': '05',\n",
    "'июня': '06',\n",
    "'июля': '07',\n",
    "'августа': '08',\n",
    "'сентября': '09',\n",
    "'октября': '10',\n",
    "'ноября': '11',\n",
    "'декабря': '12',\n",
    "}\n",
    "\n",
    "mail_news = 'https://news.mail.ru'\n",
    "yandex_news = 'https://yandex.ru/news'\n",
    "lenta_ru = 'https://lenta.ru'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "mail_links = []\n",
    "lenta_links = []\n",
    "yandex_links = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсинг \"Новости Mail.ru\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип работы:\n",
    "1. Получаем ссылку на главную новость (1 шт.), другие главные новости (4 шт. без адаптивной верстки), остальные новости (6 шт.) и получаем список mail_links.\n",
    "2. Для каждого объекта в списке переходим по ссылке при помощи функции get_item_info_mail и получаем нужные поля.\n",
    "3. Добавляем объекты в коллекцию news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_info_mail(link):\n",
    "    news_object = {}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(response.status_code)\n",
    "        return\n",
    "    \n",
    "    root = html.fromstring(response.text)\n",
    "\n",
    "    # ссылка\n",
    "    news_object['url'] = link\n",
    "\n",
    "    # заголовок\n",
    "    title = root.xpath(\"//h1[@class = 'hdr__inner']/text()\")\n",
    "    if title:\n",
    "        news_object['title'] = title[0]\n",
    "    else:\n",
    "        news_object['title'] = None\n",
    "\n",
    "    # источник\n",
    "    source_title = root.xpath(\"//span[@class = 'breadcrumbs__item']//a/span/text()\")\n",
    "    if source_title:\n",
    "        news_object['source_title'] = source_title[0]\n",
    "    else:\n",
    "        news_object['source_title'] = None\n",
    "    \n",
    "    source_url = root.xpath(\"//span[@class = 'breadcrumbs__item']//a/@href\")\n",
    "    if source_url:\n",
    "        news_object['source_url'] = source_url[0]\n",
    "\n",
    "    # дата и время\n",
    "    date_time = root.xpath(\"//span[@class = 'breadcrumbs__item']//span/@datetime\")\n",
    "    # если не получилось получить date_time, ставим текущие\n",
    "    if not date_time:\n",
    "        news_object['date'] = str(datetime.datetime.now().date())\n",
    "        news_object['time'] = str(datetime.datetime.now().time())\n",
    "\n",
    "    date_time_items = date_time[0].split('T')\n",
    "    news_object['date'] = date_time_items[0]\n",
    "    time = date_time_items[1].split('+')\n",
    "    news_object['time'] = time[0]\n",
    "\n",
    "    return news_object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_page = requests.get(mail_news, headers=headers)\n",
    "\n",
    "if not mail_page.ok:\n",
    "    print(mail_page.status_code)\n",
    "    \n",
    "root = html.fromstring(mail_page.text)\n",
    "\n",
    "# топ новость\n",
    "daily_news1 = root.xpath(\"//div[@class='daynews__item daynews__item_big']/a/@href\")[0]\n",
    "# обработка случая, когда ссылка на другой ресурс mail (например, sportmail)\n",
    "if 'http' in daily_news1:\n",
    "    daily_news1 = daily_news1\n",
    "else:\n",
    "    daily_news1_url = mail_news + daily_news1\n",
    "mail_links.append(daily_news1_url)\n",
    "\n",
    "\n",
    "# топ других новостей\n",
    "daily_news2 = root.xpath(\"//div[@class= 'daynews__item']/a/@href\")\n",
    "for item in daily_news2:\n",
    "    if 'http' in item:\n",
    "        daily_news2_url = item\n",
    "    else:\n",
    "        daily_news2_url = mail_news + item\n",
    "    mail_links.append(daily_news2_url)\n",
    "\n",
    "\n",
    "# другие новости\n",
    "daily_news3 = root.xpath(\"//ul[@class = 'list list_type_square list_half js-module']/li/a/@href\")\n",
    "for item in daily_news3:\n",
    "    if 'http' in item:\n",
    "        daily_news3_url = item\n",
    "    else:\n",
    "        daily_news3_url = mail_news + item\n",
    "    mail_links.append(daily_news3_url)\n",
    "\n",
    "\n",
    "# собираем информацию об объектах \n",
    "for link in mail_links:\n",
    "    news_obj = get_item_info_mail(link)\n",
    "\n",
    "    # пополняем коллекцию\n",
    "    obj = next(news.find({\"url\": {'$eq': news_obj['url']}}), None)\n",
    "    if not obj:\n",
    "        news.insert_one(news_obj)\n",
    "    else:\n",
    "        news.update_one({\"id\": {'$eq': news_obj['url']}},{'$set': news_obj})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.news.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсинг Lenta.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип работы:\n",
    "1. Получаем ссылку на главную новость (1 шт.) и другие главные новости (9 шт.) и получаем список lenta_links.\n",
    "2. Для каждого объекта в списке переходим по ссылке при помощи функций get_item_info_lenta и get_item_info_moslenta и получаем нужные поля.\n",
    "3. Добавляем объекты в коллекцию news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_info_moslenta(link):\n",
    "    news_object = {}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    \n",
    "    if not response.ok:\n",
    "        print(response.status_code)\n",
    "        return\n",
    "    \n",
    "    root = html.fromstring(response.text)\n",
    "\n",
    "    # ссылка\n",
    "    news_object['url'] = link\n",
    "\n",
    "    # источник\n",
    "    news_object['source_url'] = 'https://moslenta.ru/'\n",
    "    news_object['source_title'] = 'Мослента'\n",
    "\n",
    "    # заголовок\n",
    "    title = root.xpath(\"//h1[@class = 'jsx-3827467167 jsx-3813442946 headline']/text()\")\n",
    "    if title:\n",
    "        news_object['title'] = title[0]\n",
    "    else:\n",
    "        news_object['title'] = None\n",
    "\n",
    "    # дата и время\n",
    "    date_time = root.xpath(\"//div[@class = 'jsx-149585235 jsx-932351741 topline']//text()\")\n",
    "    # если не получилось получить date_time, ставим текующие\n",
    "    if not date_time:\n",
    "        news_object['date'] = str(datetime.datetime.now().date())\n",
    "        news_object['time'] = str(datetime.datetime.now().time())\n",
    "        \n",
    "    date_time = date_time[0]\n",
    "    date_time_items = date_time.split(' ')\n",
    "\n",
    "    # время\n",
    "    news_object['time'] = date_time_items[-1] + ':00'\n",
    "    \n",
    "    # дата\n",
    "    if date_time_items[0] == 'Сегодня':\n",
    "        news_object['date'] = str(datetime.date.today())\n",
    "    elif date_time_items[0] == 'Вчера':\n",
    "        news_obj['date'] = str(datetime.date.today() - datetime.timedelta(1))\n",
    "    else: \n",
    "        day = date_time_items[0]\n",
    "        month = months[date_time_items[1]]\n",
    "        year = str(datetime.datetime.now().year)\n",
    "        date = year + \"-\" + month + \"-\" + day\n",
    "        news_object['date'] = date\n",
    "    \n",
    "    return news_object\n",
    "\n",
    "\n",
    "def get_item_info_lenta(link):\n",
    "    news_object = {}\n",
    "    response = requests.get(link, headers=headers) \n",
    "    \n",
    "    if not response.ok:\n",
    "        print(response.status_code)\n",
    "        return\n",
    "\n",
    "    root = html.fromstring(response.text)\n",
    "\n",
    "    # ссылка\n",
    "    news_object['url'] = link\n",
    "\n",
    "    # источник\n",
    "    news_object['source_url'] = lenta_ru\n",
    "    news_object['source_title'] = 'Lenta.ru'\n",
    "\n",
    "    # заголовок\n",
    "    title = root.xpath(\"//h1[@class ='b-topic__title']/text()\")\n",
    "    if title:\n",
    "        news_object['title'] = title[0]\n",
    "    else:\n",
    "        news_object['title'] = None\n",
    "\n",
    "    # дата и время\n",
    "    date_time = root.xpath(\"//div[@class = 'b-topic__info']/time/@datetime\")\n",
    "    # если не получилось получить date_time, ставим текующие\n",
    "    if not date_time:\n",
    "        news_object['date'] = str(datetime.datetime.now().date())\n",
    "        news_object['time'] = str(datetime.datetime.now().time())      \n",
    "\n",
    "    date_time = date_time[0]\n",
    "    date_time_items = date_time.split('T')\n",
    "\n",
    "    news_object['date'] = date_time_items[0]\n",
    "\n",
    "    time = date_time_items[1].split('+')\n",
    "    news_object['time'] = time[0]\n",
    "\n",
    "    return news_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_page = requests.get(lenta_ru, headers=headers)\n",
    "\n",
    "if not lenta_page.ok: \n",
    "    print(lenta_page.status_code)\n",
    "    \n",
    "root = html.fromstring(lenta_page.text) \n",
    "\n",
    "# главный пост\n",
    "lead_post = root.xpath(\"//div[@class = 'first-item']/a/@href\")[0]\n",
    "# обработка случая, когда ссылка на moslenta\n",
    "if 'http' in lead_post:\n",
    "    lead_post = lead_post\n",
    "else:\n",
    "    lead_post_url = lenta_ru + lead_post\n",
    "    lenta_links.append(lead_post_url)\n",
    "\n",
    "# основные новости\n",
    "other_posts = root.xpath(\"//div[@class = 'span4']/div[@class = 'item']/a/@href\")\n",
    "for item in other_posts:\n",
    "    if 'http' in item:\n",
    "        other_post_url = item\n",
    "    else:\n",
    "        other_post_url = lenta_ru + item\n",
    "    lenta_links.append(other_post_url)\n",
    "\n",
    "for link in lenta_links:\n",
    "    if 'moslenta' in link:\n",
    "        news_obj = get_item_info_moslenta(link)\n",
    "    else:\n",
    "        news_obj = get_item_info_lenta(link)       \n",
    "\n",
    "    # пополняем коллекцию\n",
    "    obj = next(news.find({\"url\": {'$eq': news_obj['url']}}), None)\n",
    "    if not obj:\n",
    "        news.insert_one(news_obj)\n",
    "    else:\n",
    "        news.update_one({\"id\": {'$eq': news_obj['url']}},{'$set': news_obj})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.news.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсинг Яндекс.Новости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип работы: \n",
    "1. Получаем список элементов (новостей) на странице (65 шт.)\n",
    "2. Итерируемся по списку элементов и извлекаем и записываем в словарь ссылку на новость, заголовок, дату и время, название источника.\n",
    "3. Для получения ссылки на источник переходим на саму новость (функция get_source_link_yandex написана для двух видов ссылок на случай, если на главной странице есть новость из Яндекс.Спорт)\n",
    "4. Добавляем объекты в коллекцию news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения ссылки на источник с переходом на саму новость\n",
    "def get_source_link_yandex(link):\n",
    "    response = requests.get(link, headers=headers)\n",
    "    \n",
    "    if not response.ok:\n",
    "        print(response.status_code)\n",
    "        return\n",
    "        \n",
    "    root = html.fromstring(response.text)\n",
    "    \n",
    "    source_url = root.xpath(\"//h1[@class = 'story__head']//span[@class = 'story__head-agency']/a/@href\")\n",
    "    if source_url:\n",
    "        source_url = source_url[0] \n",
    "    \n",
    "    else:\n",
    "        # ссылка на источник на яндекс спорт\n",
    "        source_url = root.xpath(\"//div[@class = 'news-story__subtitle']/a/@href\")[0]\n",
    "\n",
    "    return source_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yandex_page = requests.get(yandex_news, headers=headers)\n",
    "root = html.fromstring(yandex_page.text) \n",
    "\n",
    "if not yandex_page.ok:\n",
    "    print(yandex_page.status_code)\n",
    "    \n",
    "for item in root.xpath(\"//td[@class = 'stories-set__item']\"):\n",
    "    news_object = {}\n",
    "\n",
    "    # ссылка\n",
    "    link = item.xpath(\".//h2[@class = 'story__title']/a/@href\")\n",
    "    if link:\n",
    "        link = link[0]\n",
    "        news_object['url'] = 'https://yandex.ru' + link\n",
    "        # ссылка на источник (только в случае возможности получить ссылку на новость)\n",
    "        news_object['source_url'] = get_source_link_yandex(news_object['url'])\n",
    "    else:\n",
    "        news_object['url'] = None\n",
    "\n",
    "    # заголовок\n",
    "    title = item.xpath(\".//h2[@class = 'story__title']/a/text()\")\n",
    "    if title:\n",
    "        news_object['title'] = title[0]\n",
    "    else:\n",
    "        news_object['title']  = None\n",
    "\n",
    "    # дата, время и источник\n",
    "    date_and_source = item.xpath(\".//div[@class = 'story__date']/text()\")\n",
    "    \n",
    "    # если элемент не найден - то ставим  current timestamp \n",
    "    if not date_and_source:\n",
    "        news_object['date'] = str(datetime.datetime.now().date())\n",
    "        news_object['time'] = str(datetime.datetime.now().time())\n",
    "        news_object['source_title'] = None\n",
    "\n",
    "    \n",
    "    date_and_source = date_and_source[0]\n",
    "    items = date_and_source.split(' ')\n",
    "    \n",
    "    # название источника\n",
    "    news_object['source_title'] = ' '.join(items[:-1])\n",
    "\n",
    "    # дата и время\n",
    "    # сегодня (без указания даты)\n",
    "    if '\\xa0' not in items[-1]:\n",
    "        news_object['time'] = items[-1] + ':00'\n",
    "        news_object['date'] = str(datetime.date.today())  \n",
    "\n",
    "    # вчера\n",
    "    elif 'вчера' in items[-1]:\n",
    "        time_complex = items[-1].split('\\xa0')\n",
    "        news_object['time'] = time_complex[-1] + ':00'\n",
    "        news_object['date'] = str(datetime.date.today() - datetime.timedelta(1)) \n",
    "\n",
    "    # если указаны число и месяц (напр., 18 апреля в 22:41)\n",
    "    else:\n",
    "        time_complex = items[-1].split('\\xa0')\n",
    "        news_object['time'] = time_complex[-1] + ':00'\n",
    "\n",
    "        day = time_complex[0]\n",
    "        month = months[time_complex[1]]\n",
    "        year = str(datetime.datetime.now().year)\n",
    "        date = year + \"-\" + month + \"-\" + day\n",
    "        news_object['date'] = date\n",
    "\n",
    "\n",
    "    # пополняем коллекцию\n",
    "    obj = next(news.find({\"url\": {'$eq': news_object['url']}}), None)\n",
    "    if not obj:\n",
    "        news.insert_one(news_object)\n",
    "    else:\n",
    "        news.update_one({\"id\": {'$eq': news_object['url']}},{'$set': news_object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.news.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_url</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e9d6829b8a16c0325a84af3</td>\n",
       "      <td>https://news.mail.ru/society/41460513/</td>\n",
       "      <td>В России число заболевших коронавирусом превыс...</td>\n",
       "      <td>Интерфакс</td>\n",
       "      <td>http://www.interfax.ru/</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>11:02:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e9d6829b8a16c0325a84af4</td>\n",
       "      <td>https://news.mail.ru/society/41458830/</td>\n",
       "      <td>Треть россиян поддерживают возможный перенос м...</td>\n",
       "      <td>Коммерсантъ</td>\n",
       "      <td>http://www.kommersant.ru</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>09:58:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e9d6829b8a16c0325a84af5</td>\n",
       "      <td>https://news.mail.ru/society/41455831/</td>\n",
       "      <td>Названы российские регионы с приростом населения</td>\n",
       "      <td>РИА Новости</td>\n",
       "      <td>http://www.ria.ru</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>00:42:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e9d6829b8a16c0325a84af6</td>\n",
       "      <td>https://news.mail.ru/incident/41456152/</td>\n",
       "      <td>У скончавшейся у подъезда москвички не выявлен...</td>\n",
       "      <td>Известия</td>\n",
       "      <td>http://iz.ru/</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>01:40:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e9d682ab8a16c0325a84af7</td>\n",
       "      <td>https://news.mail.ru/incident/41458627/</td>\n",
       "      <td>В МВД рассказали, что мошенники все чаще ворую...</td>\n",
       "      <td>ТАСС</td>\n",
       "      <td>http://www.tass.ru/</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>10:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5e9d6842b8a16c0325a84b43</td>\n",
       "      <td>https://yandex.ru/news/story/Mercedes-Benz_otz...</td>\n",
       "      <td>Mercedes-Benz отзывает около 500 автомобилей в...</td>\n",
       "      <td>32CARS.ru</td>\n",
       "      <td>https://www.32cars.ru/world-news/date-20-04-20...</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5e9d6842b8a16c0325a84b44</td>\n",
       "      <td>https://yandex.ru/news/story/Legendarnomu_VAZ-...</td>\n",
       "      <td>Легендарному ВАЗ-2101 исполнилось 50 лет</td>\n",
       "      <td>Автоновости дня</td>\n",
       "      <td>https://avtonovostidnya.ru/avtoprom/192112?utm...</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>11:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5e9d6842b8a16c0325a84b45</td>\n",
       "      <td>https://yandex.ru/news/story/Novyj_krossover_S...</td>\n",
       "      <td>Новый кроссовер Subaru получит имя Evoltis</td>\n",
       "      <td>Автоновости дня</td>\n",
       "      <td>https://avtonovostidnya.ru/novinki/192269-suba...</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>11:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5e9d6843b8a16c0325a84b46</td>\n",
       "      <td>https://yandex.ru/news/story/Haval_F7_stal_sam...</td>\n",
       "      <td>Haval F7 стал самым популярным китайским автом...</td>\n",
       "      <td>Автоновости дня</td>\n",
       "      <td>https://avtonovostidnya.ru/avtorynok/192119-ha...</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>10:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5e9d6843b8a16c0325a84b47</td>\n",
       "      <td>https://yandex.ru/news/story/Volkswagen_polnos...</td>\n",
       "      <td>Volkswagen полностью рассекретил минивэн Viloran</td>\n",
       "      <td>RuNews24.ru</td>\n",
       "      <td>https://runews24.ru/auto/20/04/2020/64b130235f...</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>10:47:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id  \\\n",
       "0   5e9d6829b8a16c0325a84af3   \n",
       "1   5e9d6829b8a16c0325a84af4   \n",
       "2   5e9d6829b8a16c0325a84af5   \n",
       "3   5e9d6829b8a16c0325a84af6   \n",
       "4   5e9d682ab8a16c0325a84af7   \n",
       "..                       ...   \n",
       "80  5e9d6842b8a16c0325a84b43   \n",
       "81  5e9d6842b8a16c0325a84b44   \n",
       "82  5e9d6842b8a16c0325a84b45   \n",
       "83  5e9d6843b8a16c0325a84b46   \n",
       "84  5e9d6843b8a16c0325a84b47   \n",
       "\n",
       "                                                  url  \\\n",
       "0              https://news.mail.ru/society/41460513/   \n",
       "1              https://news.mail.ru/society/41458830/   \n",
       "2              https://news.mail.ru/society/41455831/   \n",
       "3             https://news.mail.ru/incident/41456152/   \n",
       "4             https://news.mail.ru/incident/41458627/   \n",
       "..                                                ...   \n",
       "80  https://yandex.ru/news/story/Mercedes-Benz_otz...   \n",
       "81  https://yandex.ru/news/story/Legendarnomu_VAZ-...   \n",
       "82  https://yandex.ru/news/story/Novyj_krossover_S...   \n",
       "83  https://yandex.ru/news/story/Haval_F7_stal_sam...   \n",
       "84  https://yandex.ru/news/story/Volkswagen_polnos...   \n",
       "\n",
       "                                                title     source_title  \\\n",
       "0   В России число заболевших коронавирусом превыс...        Интерфакс   \n",
       "1   Треть россиян поддерживают возможный перенос м...      Коммерсантъ   \n",
       "2    Названы российские регионы с приростом населения      РИА Новости   \n",
       "3   У скончавшейся у подъезда москвички не выявлен...         Известия   \n",
       "4   В МВД рассказали, что мошенники все чаще ворую...             ТАСС   \n",
       "..                                                ...              ...   \n",
       "80  Mercedes-Benz отзывает около 500 автомобилей в...        32CARS.ru   \n",
       "81           Легендарному ВАЗ-2101 исполнилось 50 лет  Автоновости дня   \n",
       "82         Новый кроссовер Subaru получит имя Evoltis  Автоновости дня   \n",
       "83  Haval F7 стал самым популярным китайским автом...  Автоновости дня   \n",
       "84   Volkswagen полностью рассекретил минивэн Viloran      RuNews24.ru   \n",
       "\n",
       "                                           source_url        date      time  \n",
       "0                             http://www.interfax.ru/  2020-04-20  11:02:38  \n",
       "1                            http://www.kommersant.ru  2020-04-20  09:58:57  \n",
       "2                                   http://www.ria.ru  2020-04-20  00:42:37  \n",
       "3                                       http://iz.ru/  2020-04-20  01:40:13  \n",
       "4                                 http://www.tass.ru/  2020-04-20  10:21:06  \n",
       "..                                                ...         ...       ...  \n",
       "80  https://www.32cars.ru/world-news/date-20-04-20...  2020-04-20  12:00:00  \n",
       "81  https://avtonovostidnya.ru/avtoprom/192112?utm...  2020-04-20  11:19:00  \n",
       "82  https://avtonovostidnya.ru/novinki/192269-suba...  2020-04-20  11:58:00  \n",
       "83  https://avtonovostidnya.ru/avtorynok/192119-ha...  2020-04-20  10:17:00  \n",
       "84  https://runews24.ru/auto/20/04/2020/64b130235f...  2020-04-20  10:47:00  \n",
       "\n",
       "[85 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(news.find({}))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('news.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
