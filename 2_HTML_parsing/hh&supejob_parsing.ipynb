{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг HTML. BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке реализован парсинг основной информации по вакансиям с сайтов hh.ru и superjob.ru.\n",
    "Пользователь может передать через input ключевые слова для поиска и регион (поиск работает для 12-ти крупных российских городов). Приложение анализирует все доступные страницы поиска.\n",
    "Результат работы парсера сохраняется в \\*.csv файл, содержащий следующие поля:\n",
    "\n",
    "- Должность\n",
    "- Зарплата (отдельно минимум, максимум и валюта)\n",
    "- Работодатель\n",
    "- Cсылка на вакансию\n",
    "- Источник вакансии\n",
    "- Описание вакансии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите запрос: machine learning\n",
      "Введите город для поиска: мск\n"
     ]
    }
   ],
   "source": [
    "# параметры поиска\n",
    "query = input('Введите запрос: ').lower()\n",
    "area = input('Введите город для поиска: ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь для результатов поиска\n",
    "vacancies = {\n",
    "    'query': f'{query}_{area}',\n",
    "    'results': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словари для трансформации региона поиска\n",
    "hh_area_dict = {\n",
    "    'москва': '1',\n",
    "    'санкт-петербург': '2',\n",
    "    'екатеринбург': '3',\n",
    "    'новосибирск': '4',\n",
    "    'нижний новгород': '66',\n",
    "    'казань': '88',\n",
    "    'воронеж': '26',\n",
    "    'волгоград': '24',\n",
    "    'ростов-на-дону': '76',\n",
    "    'краснодар': '53',\n",
    "    'уфа': '99', \n",
    "    'хабаровск': '102'\n",
    "}\n",
    "\n",
    "sj_area_dict = {\n",
    "    'москва': 'москва',\n",
    "    'санкт-петербург': 'spb',\n",
    "    'екатеринбург': 'ekaterinburg',\n",
    "    'новосибирск': 'nsk',\n",
    "    'нижний новгород': 'nn',\n",
    "    'казань': 'kazan',\n",
    "    'воронеж': 'voronezh',\n",
    "    'волгоград': 'volgograd',\n",
    "    'ростов-на-дону': 'rnd',\n",
    "    'краснодар': 'krasnodar',\n",
    "    'уфа': 'ufa', \n",
    "    'хабаровск': 'habarovsk'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразовываем input в понятный парсеру\n",
    "if area in ['москва', 'мск']:\n",
    "    hh_area = hh_area_dict['москва']\n",
    "    sj_area = sj_area_dict['москва']\n",
    "    \n",
    "elif area in ['санкт-петербург', 'спб']:\n",
    "    hh_area = hh_area_dict['санкт-петербург']\n",
    "    sj_area = sj_area_dict['санкт-петербург']\n",
    "    \n",
    "elif area in ['екатеринбург', 'екб']:\n",
    "    hh_area = hh_area_dict['екатеринбург']\n",
    "    sj_area = sj_area_dict['екатеринбург']\n",
    "    \n",
    "elif area == 'новосибирск':\n",
    "    hh_area = hh_area_dict['новосибирск']\n",
    "    sj_area = sj_area_dict['новосибирск']\n",
    "\n",
    "elif area == 'нижний новгород':\n",
    "    hh_area = hh_area_dict['нижний новгород']\n",
    "    sj_area = sj_area_dict['нижний новгород']\n",
    "\n",
    "elif area == 'казань':\n",
    "    hh_area = hh_area_dict['казань']\n",
    "    sj_area = sj_area_dict['казань']\n",
    "\n",
    "elif area == 'воронеж':\n",
    "    hh_area = hh_area_dict['воронеж']\n",
    "    sj_area = sj_area_dict['воронеж']   \n",
    "\n",
    "elif area == 'волгоград':\n",
    "    hh_area = hh_area_dict['волгоград']\n",
    "    sj_area = sj_area_dict['волгоград']\n",
    "\n",
    "elif area in ['ростов-на-дону', 'рнд']:\n",
    "    hh_area = hh_area_dict['ростов-на-дону']\n",
    "    sj_area = sj_area_dict['ростов-на-дону']\n",
    "\n",
    "elif area == 'краснодар':\n",
    "    hh_area = hh_area_dict['краснодар']\n",
    "    sj_area = sj_area_dict['краснодар']  \n",
    "\n",
    "elif area == 'уфа':\n",
    "    hh_area = hh_area_dict['уфа']\n",
    "    sj_area = sj_area_dict['уфа']\n",
    "\n",
    "elif area == 'хабаровск':\n",
    "    hh_area = hh_area_dict['хабаровск']\n",
    "    sj_area = sj_area_dict['хабаровск']  \n",
    "    \n",
    "else:\n",
    "    print('Неизвестный регион')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = 'https://hh.ru/'\n",
    "sj = 'https://www.superjob.ru'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:74.0) Gecko/20100101 Firefox/74.0'}\n",
    "\n",
    "# задаем счетчики страниц - у hh - c 0, у sj - c 1\n",
    "hh_page_count = range(100)\n",
    "sj_page_count = range(1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hh.ru parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hh_page_count:\n",
    "    hh_link = f'{hh}search/vacancy?area={hh_area}&st=searchVacancy&text={query}&page={i}'\n",
    "    hh_page = requests.get(hh_link, headers=headers)\n",
    "    \n",
    "    if not hh_page.ok:\n",
    "        break\n",
    "    \n",
    "    # формируем список элементов страницы, содержащих вакансии\n",
    "    hh_soup = bs(hh_page.text,'lxml')\n",
    "    vacancies_block = hh_soup.find_all('div', {'class': 'vacancy-serp'})[0]\n",
    "    vacancies_list = vacancies_block.find_all('div', {'class': 'vacancy-serp-item'})\n",
    "    \n",
    "    # определяем условие выхода из цикла (вакансий больше нет)\n",
    "    if len(vacancies_list) == 0:\n",
    "        break\n",
    "    \n",
    "    # итерируемся по списку, содержащем вакансии\n",
    "    for vacancy in vacancies_list:\n",
    "        vacancy_data = {}\n",
    "        \n",
    "        # название вакансии\n",
    "        title = vacancy.findChildren('a', {'data-qa': 'vacancy-serp__vacancy-title'})[0].getText()\n",
    "\n",
    "        \n",
    "        #  зарплата\n",
    "        salary = None\n",
    "        \n",
    "        salary_el = vacancy.findChildren('span', {'data-qa': \"vacancy-serp__vacancy-compensation\"})\n",
    "        \n",
    "        if salary_el:\n",
    "            salary = {\n",
    "                'min': None,\n",
    "                'max': None,\n",
    "                'curr': None\n",
    "            }\n",
    "            \n",
    "            # получаем значения из строки\n",
    "            split_range = re.split('-', salary_el[0].getText())\n",
    "            if len(split_range) == 2:\n",
    "                salary['min'] = ''.join(re.findall('\\d+', split_range[0]))\n",
    "                items = re.findall('\\w+', split_range[1])\n",
    "                salary['max'] = ''.join(items[:-1])\n",
    "                salary['curr'] = items[-1] \n",
    "            else:\n",
    "                items = re.findall('\\w+', split_range[0])\n",
    "                if items[0] == 'от':\n",
    "                    salary['min'] = ''.join(items[1:-1])\n",
    "                else:\n",
    "                    salary['max'] = ''.join(items[1:-1])          \n",
    "                salary['curr'] = items[-1]\n",
    "            \n",
    "            \n",
    "        # работадатель\n",
    "        employer_el = vacancy.findChildren('a', {'data-qa': 'vacancy-serp__vacancy-employer'})\n",
    "        \n",
    "        # обрабатываем случай, когда работодатель указан описательно (нет ссылки на компанию)\n",
    "        if employer_el:\n",
    "            employer = employer_el[0].getText()\n",
    "        else:\n",
    "            employer = vacancy.findChildren('div', {'class': 'vacancy-serp-item__meta-info'})[0].getText()              \n",
    "\n",
    "            \n",
    "        # ссылка\n",
    "        vac_url = vacancy.findChildren('a', {'data-qa': 'vacancy-serp__vacancy-title'})[0]['href']\n",
    "        \n",
    "        \n",
    "        # описание\n",
    "        desc1 = vacancy.findChildren('div', {'data-qa': 'vacancy-serp__vacancy_snippet_responsibility'})[0].getText()\n",
    "        desc2 = vacancy.findChildren('div', {'data-qa': 'vacancy-serp__vacancy_snippet_requirement'})[0].getText()\n",
    "        \n",
    "        \n",
    "        # записываем полученные значения в словарь по каждой вакансии\n",
    "        vacancy_data['title'] = title\n",
    "        vacancy_data['salary'] = salary\n",
    "        vacancy_data['employer'] = employer\n",
    "        vacancy_data['url'] = vac_url\n",
    "        vacancy_data['source'] = hh\n",
    "        vacancy_data['short_desc'] = desc1 + desc2\n",
    "        \n",
    "        # пополняем основной словарь вакансий\n",
    "        vacancies['results'].append(vacancy_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Superjob.ru parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in sj_page_count:\n",
    "    \n",
    "    # обрабатываем случай, когда регион 'москва'\n",
    "    if sj_area == 'москва':\n",
    "        sj_link = f'{sj}/vacancy/search/?keywords={query}&geo[t][0]=4&page={i}'\n",
    "    else:\n",
    "        sj_link = f'https://{sj_area}.superjob.ru/vacancy/search/?keywords={query}&page={i}'\n",
    "    \n",
    "    sj_page = requests.get(sj_link, headers=headers)\n",
    "\n",
    "    if sj_page.ok:\n",
    "        \n",
    "        # записываем нужные классы в переменные для лаконичности\n",
    "        vac_block = '_1Ttd8 _2CsQi'\n",
    "        vac_class = '_3zucV f-test-vacancy-item _3j3cA RwN9e _3tNK- _1NStQ _1I1pc'        \n",
    "        title_url_class = '_3mfro CuJz5 PlM3e _2JVkc _3LJqf'\n",
    "        salary_class = '_3mfro _2Wp8I _31tpt f-test-text-company-item-salary PlM3e _2JVkc _2VHxz'\n",
    "        employer_class = '_3mfro _3Fsn4 f-test-text-vacancy-item-company-name _9fXTd _2JVkc _2VHxz _15msI'\n",
    "        location = '_3mfro f-test-text-company-item-location _9fXTd _2JVkc _2VHxz'\n",
    "        desc_class = '_3mfro _3V-Qt _9fXTd _2JVkc _2VHxz'\n",
    "        \n",
    "        # формируем список элементов страницы, содержащих вакансии\n",
    "        sj_soup = bs(sj_page.text,'lxml')\n",
    "        vacancies_block = sj_soup.find_all('div', {'class': vac_block})[0]\n",
    "        vacancies_list = vacancies_block.find_all('div', {'class': vac_class})\n",
    "    \n",
    "        # определяем условие выхода из цикла (вакансий больше нет)\n",
    "        if len(vacancies_list) == 0:\n",
    "            break\n",
    "        \n",
    "        # итерируемся по списку, содержащем вакансии\n",
    "        for vacancy in vacancies_list:\n",
    "            vacancy_data = {}\n",
    "          \n",
    "        \n",
    "            # название вакансии\n",
    "            title = vacancy.findChildren('div', {'class': title_url_class})\n",
    "            \n",
    "            # обрабатываем случай, когда title лежит не в span, а в h2\n",
    "            if title:\n",
    "                title = title[0].getText()\n",
    "            else:\n",
    "                title = vacancy.findChildren('h2', {'class': title_url_class})[0].getText()\n",
    "            \n",
    "            \n",
    "            # зарплата\n",
    "            salary_el = vacancy.findChildren('span', {'class': salary_class})[0].getText()\n",
    "            \n",
    "            if salary_el == 'По договорённости':\n",
    "                salary = None\n",
    "            else:\n",
    "\n",
    "                salary = {\n",
    "                    'min': None,\n",
    "                    'max': None,\n",
    "                    'curr': None\n",
    "                }\n",
    "\n",
    "                salary_el = salary_el.replace('\\xa0', ' ')\n",
    "                split_range = re.split('—', salary_el)\n",
    "\n",
    "                if len(split_range) == 2:\n",
    "                    salary['min'] = ''.join(re.findall('\\d+', split_range[0]))\n",
    "                    items = re.findall('\\w+', split_range[1])\n",
    "                    salary['max'] = ''.join(items[:-1])\n",
    "                    salary['curr'] = items[-1] \n",
    "                else:\n",
    "                    items = re.findall('\\w+', split_range[0])\n",
    "                    if items[0] == 'от':\n",
    "                        salary['min'] = ''.join(items[1:-1])\n",
    "                    else:\n",
    "                        salary['max'] = ''.join(items[1:-1])          \n",
    "                    salary['curr'] = items[-1] \n",
    "                    \n",
    "            # работодатель\n",
    "            employer_el = vacancy.findChildren('span', {'class':employer_class})\n",
    "            \n",
    "            # обрабатываем случай, когда работодатель не указан\n",
    "            if employer_el:\n",
    "                employer = employer_el[0].getText()\n",
    "            else:\n",
    "                employer = None\n",
    "        \n",
    "        \n",
    "            # ссылка\n",
    "            url = vacancy.findChildren('div', {'class': title_url_class})\n",
    "            \n",
    "            # обрабатываем случай, когда url лежит не в span, а в h2\n",
    "            if url:\n",
    "                url = url[0].find('a')['href']\n",
    "                vac_url = sj + url             \n",
    "            else:\n",
    "                url = vacancy.findChildren('h2', {'class': title_url_class})[0].find('a')['href']\n",
    "                vac_url = sj + url\n",
    "\n",
    "                \n",
    "            # описание\n",
    "            desc_el = vacancy.findChildren('span', {'class': desc_class})\n",
    "            \n",
    "            # обрабатываем случай, когда описания вакансии нет\n",
    "            if desc_el:\n",
    "                desc = desc_el[0].getText()\n",
    "            else:\n",
    "                desc = None\n",
    "             \n",
    "            \n",
    "            # записываем полученные значения в словарь по каждой вакансии\n",
    "            vacancy_data['title'] = title\n",
    "            vacancy_data['salary'] = salary\n",
    "            vacancy_data['employer'] = employer\n",
    "            vacancy_data['url'] = vac_url\n",
    "            vacancy_data['source'] = sj\n",
    "            vacancy_data['short_desc'] = desc\n",
    "            \n",
    "            # пополняем основной словарь вакансий\n",
    "            vacancies['results'].append(vacancy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обрабатываем случай, если по запросу ничего не найдено\n",
    "hh_counter = 0\n",
    "sj_counter = 0\n",
    "\n",
    "for i in vacancies['results']:\n",
    "    if i['source'] == hh:\n",
    "        hh_counter += 1\n",
    "    else:\n",
    "        sj_counter +=1\n",
    "        \n",
    "if hh_counter == 0 and sj_counter == 0:\n",
    "    print('По данному запросу ничего не найдено')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_counter, sj_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    }
   ],
   "source": [
    "print(len(vacancies['results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>employer</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>short_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C++/Deep Learning/ Machine Learning Developer ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Сбербанк для экспертов</td>\n",
       "      <td>https://kolomna.hh.ru/vacancy/35671395?query=m...</td>\n",
       "      <td>https://hh.ru/</td>\n",
       "      <td>Предстоит разрабатывать сервис для распознаван...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Machine Learning Developer</td>\n",
       "      <td>None</td>\n",
       "      <td>ООО Фабрика информационных технологий</td>\n",
       "      <td>https://kolomna.hh.ru/vacancy/36632357?query=m...</td>\n",
       "      <td>https://hh.ru/</td>\n",
       "      <td>Заниматься командной разработкой новых продукт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>{'min': '300000', 'max': None, 'curr': 'руб'}</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>https://kolomna.hh.ru/vacancy/36359628?query=m...</td>\n",
       "      <td>https://hh.ru/</td>\n",
       "      <td>...теория вероятностей, матанализ. Английский ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>АО Первая Грузовая Компания</td>\n",
       "      <td>https://kolomna.hh.ru/vacancy/36353277?query=m...</td>\n",
       "      <td>https://hh.ru/</td>\n",
       "      <td>Участие в реализации проектов по разработке ПО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аналитик-математик / Junior Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Связной</td>\n",
       "      <td>https://kolomna.hh.ru/vacancy/30250465?query=m...</td>\n",
       "      <td>https://hh.ru/</td>\n",
       "      <td>Исследование данных методами математической ст...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  C++/Deep Learning/ Machine Learning Developer ...   \n",
       "1                  Senior Machine Learning Developer   \n",
       "2                              Senior Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4           Аналитик-математик / Junior Data Analyst   \n",
       "\n",
       "                                          salary  \\\n",
       "0                                           None   \n",
       "1                                           None   \n",
       "2  {'min': '300000', 'max': None, 'curr': 'руб'}   \n",
       "3                                           None   \n",
       "4                                           None   \n",
       "\n",
       "                                employer  \\\n",
       "0                 Сбербанк для экспертов   \n",
       "1  ООО Фабрика информационных технологий   \n",
       "2                               Gradient   \n",
       "3            АО Первая Грузовая Компания   \n",
       "4                                Связной   \n",
       "\n",
       "                                                 url          source  \\\n",
       "0  https://kolomna.hh.ru/vacancy/35671395?query=m...  https://hh.ru/   \n",
       "1  https://kolomna.hh.ru/vacancy/36632357?query=m...  https://hh.ru/   \n",
       "2  https://kolomna.hh.ru/vacancy/36359628?query=m...  https://hh.ru/   \n",
       "3  https://kolomna.hh.ru/vacancy/36353277?query=m...  https://hh.ru/   \n",
       "4  https://kolomna.hh.ru/vacancy/30250465?query=m...  https://hh.ru/   \n",
       "\n",
       "                                          short_desc  \n",
       "0  Предстоит разрабатывать сервис для распознаван...  \n",
       "1  Заниматься командной разработкой новых продукт...  \n",
       "2  ...теория вероятностей, матанализ. Английский ...  \n",
       "3  Участие в реализации проектов по разработке ПО...  \n",
       "4  Исследование данных методами математической ст...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancies_df = pd.DataFrame(vacancies['results'])\n",
    "vacancies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancies_df.to_csv(f'{vacancies[\"query\"]}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
